# Softmax
An activation function is a function used in artificial neural networks which outputs a small value for small inputs, and a larger value if its inputs exceed a threshold. I compared Sigmoid and Softmax activation functions, then demonstrated the differences in Python.  https://youtu.be/2MEo6Jmeaco
